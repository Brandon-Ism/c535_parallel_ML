{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2trMojzDtqJE",
        "outputId": "69c0fc40-777b-425e-edb7-d84b72ee888b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov  7 06:58:50 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "final_df = pd.read_csv('processed_reviews.csv')"
      ],
      "metadata": {
        "id": "i1DFhq8e0cSy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "final_df = pd.read_csv('processed_reviews.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "final_df.dropna(inplace=True)\n",
        "X = final_df[\"reviewText\"]\n",
        "y = final_df['class']  # Assuming 'class' is your target label (fake or real review)\n",
        "\n",
        "# 1. Use TF-IDF with a limited number of features to reduce memory usage\n",
        "vectorizer = TfidfVectorizer(max_features=15000)  # Limit to 15000 features\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the training and testing sets\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Custom dataset class to handle sparse tensors\n",
        "class SparseDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X_row = self.X[idx].toarray().squeeze()\n",
        "        y_row = self.y[idx]\n",
        "        return torch.tensor(X_row, dtype=torch.float32), torch.tensor(y_row, dtype=torch.float32)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SparseDataset(X_train_vectorized, y_train.values)\n",
        "test_dataset = SparseDataset(X_test_vectorized, y_test.values)\n",
        "\n",
        "# Custom collate function to handle sparse tensors\n",
        "def sparse_collate_fn(batch):\n",
        "    X_batch, y_batch = zip(*batch)\n",
        "    X_batch = torch.stack(X_batch)\n",
        "    y_batch = torch.stack(y_batch).view(-1, 1)  # Reshape y_batch to have the same shape as y_pred\n",
        "    return X_batch.cuda(), y_batch.cuda()\n",
        "\n",
        "# Use DataLoader for efficient batch processing on GPU with custom collate_fn\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=sparse_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=sparse_collate_fn)\n",
        "\n",
        "# Simplified model\n",
        "class SimpleSpamReviewClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleSpamReviewClassifier, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "# Initialize the model and move it to GPU\n",
        "model = SimpleSpamReviewClassifier(input_size=15000).cuda()\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "# Calculate training time\n",
        "training_time = time.time() - start_time\n",
        "print(f\"Training time: {training_time / 60:.2f} minutes\")\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLy0mDdq2WjY",
        "outputId": "24c3e2cb-bdfe-4783-dd92-da788e0a554c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.16634905338287354\n",
            "Epoch 2/5, Loss: 0.09135850518941879\n",
            "Epoch 3/5, Loss: 0.1582503616809845\n",
            "Epoch 4/5, Loss: 0.38319510221481323\n",
            "Epoch 5/5, Loss: 0.20873790979385376\n",
            "Training time: 26.10 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            y_pred = model(X_batch)\n",
        "            test_loss += criterion(y_pred, y_batch).item()\n",
        "            pred = (y_pred > 0.5).float()  # Convert probabilities to binary predictions\n",
        "            correct += pred.eq(y_batch).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "    return test_loss, accuracy\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saeK--XA68aY",
        "outputId": "53e747bf-202d-44a5-ad63-1d1220b83f3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0067, Test Accuracy: 0.9152\n"
          ]
        }
      ]
    }
  ]
}