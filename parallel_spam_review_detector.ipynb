{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lm_h5T5fx1y",
        "outputId": "4666f6c3-8594-45fd-c9a9-1eaf87c46455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Oct 10 09:42:07 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsqefP2wcXOw",
        "outputId": "ba2f2ab6-bf5b-4c27-9244-83c93a29e80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                    _id      reviewerID        asin  \\\n",
            "0  {'$oid': '5a13282b741a2384e879a620'}  A3C9CSW3TJITGT  0005069491   \n",
            "1  {'$oid': '5a13282b741a2384e879a621'}  A31POTIYCKSZ9G  0076561046   \n",
            "2  {'$oid': '5a13282b741a2384e879a622'}  A2GGHHME9B6W4O  0131358936   \n",
            "3  {'$oid': '5a13282b741a2384e879a61f'}   AMEVO2LY6VEJA  0000191639   \n",
            "4  {'$oid': '5a13282b741a2384e879a623'}  A1FSLDH43ORWZP  0133642984   \n",
            "\n",
            "    reviewerName helpful                                         reviewText  \\\n",
            "0          Renee  [0, 0]  I love these felt nursery rhyme characters and...   \n",
            "1  So CA Teacher  [0, 0]  I see no directions for its use. Therefore I h...   \n",
            "2     Dalilah G.  [0, 0]  This is a great tool for any teacher using the...   \n",
            "3  Nicole Soeder  [0, 0]  Great product, thank you! Our son loved the pu...   \n",
            "4  Dayna English  [0, 0]  Although not as streamlined as the Algebra I m...   \n",
            "\n",
            "   overall                                     summary  unixReviewTime  \\\n",
            "0        4  Charming characters but busy work required      1377561600   \n",
            "1        3                    No directions for use...      1404864000   \n",
            "2        5                                Great CD-ROM      1382400000   \n",
            "3        5                                     Puzzles      1388016000   \n",
            "4        5        Algebra II -- presentation materials      1374278400   \n",
            "\n",
            "    reviewTime        category  class  \n",
            "0  08 27, 2013  Toys_and_Games      1  \n",
            "1   07 9, 2014  Toys_and_Games      0  \n",
            "2  10 22, 2013  Toys_and_Games      1  \n",
            "3  12 26, 2013  Toys_and_Games      1  \n",
            "4  07 20, 2013  Toys_and_Games      1  \n",
            "Index(['_id', 'reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
            "       'overall', 'summary', 'unixReviewTime', 'reviewTime', 'category',\n",
            "       'class'],\n",
            "      dtype='object')\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1997140 entries, 0 to 1997139\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Dtype \n",
            "---  ------          ----- \n",
            " 0   _id             object\n",
            " 1   reviewerID      object\n",
            " 2   asin            object\n",
            " 3   reviewerName    object\n",
            " 4   helpful         object\n",
            " 5   reviewText      object\n",
            " 6   overall         int64 \n",
            " 7   summary         object\n",
            " 8   unixReviewTime  int64 \n",
            " 9   reviewTime      object\n",
            " 10  category        object\n",
            " 11  class           int64 \n",
            "dtypes: int64(3), object(9)\n",
            "memory usage: 182.8+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Verify the file path\n",
        "file_path = r\"Toys_and_Games.json\"\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"The file at {file_path} does not exist.\")\n",
        "\n",
        "# Load the dataset from the JSON Lines file\n",
        "try:\n",
        "    data = pd.read_json(file_path, lines=True)\n",
        "except ValueError as e:\n",
        "    raise ValueError(f\"Error reading JSON Lines file: {e}\")\n",
        "\n",
        "# Explore the data (look at the first few rows)\n",
        "print(data.head())   # Check the first few rows of the dataset\n",
        "print(data.columns)  # Check the column names\n",
        "print(data.info())   # Get a summary of the data types and null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFtIQsDIjIM_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "\n",
        "# 1. Preprocess the data (drop missing values and split into features/target)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "X = data[\"reviewText\"]\n",
        "y = data['class']  # Assuming 'class' is your target label (fake or real review)\n",
        "\n",
        "# 2. Prepare the vectorizer (TF-IDF)\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# 3. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Vectorize the training and testing sets\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# 5. Define a generator function to yield mini-batches of data\n",
        "def batch_generator(X, y, batch_size=32):\n",
        "    num_batches = X.shape[0] // batch_size\n",
        "    for i in range(num_batches + 1):\n",
        "        X_batch = X[i * batch_size : (i + 1) * batch_size]\n",
        "        y_batch = y[i * batch_size : (i + 1) * batch_size]\n",
        "        yield X_batch.toarray(), y_batch  # Convert to dense inside generator\n",
        "\n",
        "# 6. Convert labels to tensor\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Use the batch_generator inside your training loop later\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vaa46g4pC19"
      },
      "outputs": [],
      "source": [
        "# Build the torch Logistic Regression model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.sigmoid(self.linear(x)).squeeze(1)  # Use squeeze to remove extra dimension\n",
        "        return out\n",
        "\n",
        "\n",
        "# innitiate the model\n",
        "input_dim = X_train_vectorized.shape[1]\n",
        "model = LogisticRegression(input_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM0dw3cxsPI2"
      },
      "outputs": [],
      "source": [
        "# RUN MODEL ON GPU\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Custom Dataset to handle sparse data\n",
        "class SparseTensorDataset(Dataset):\n",
        "    def __init__(self, X_sparse, y):\n",
        "        self.X_sparse = csr_matrix(X_sparse)  # Store sparse matrix\n",
        "        self.y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X_sparse.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Convert each sample on the fly to dense\n",
        "        X_dense = torch.tensor(self.X_sparse[idx].toarray(), dtype=torch.float32)\n",
        "        y = self.y[idx]\n",
        "        return X_dense, y\n",
        "\n",
        "# 1. Create SparseTensorDataset instead of dense TensorDataset\n",
        "train_dataset = SparseTensorDataset(X_train_vectorized, y_train)\n",
        "test_dataset = SparseTensorDataset(X_test_vectorized, y_test)\n",
        "\n",
        "# 2. Use DataLoader for mini-batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=2000, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2000, shuffle=False)\n",
        "\n",
        "# 3. Move model to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = LogisticRegression(input_dim).to(device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JODZNpOTsx1o"
      },
      "outputs": [],
      "source": [
        "# # RUN MODEL ON CPU\n",
        "\n",
        "# # Convert data to Pytorch tensor\n",
        "# X_train_tensor = torch.tensor(X_train_vectorized.toarray(), dtype=torch.float32)\n",
        "# y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# X_test_tensor = torch.tensor(X_test_vectorized.toarray(), dtype=torch.float32)\n",
        "# y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4iIq6OvpazW"
      },
      "outputs": [],
      "source": [
        "# Define the Loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL3LeWF6qd8P"
      },
      "outputs": [],
      "source": [
        "# Evaluation loop (same idea as above)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        predictions = outputs.round()\n",
        "        total += y_batch.size(0)\n",
        "        correct += (predictions == y_batch).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
